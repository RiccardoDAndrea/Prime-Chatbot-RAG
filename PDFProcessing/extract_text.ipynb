{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing the chucking process\n",
    "import os\n",
    "import pdfplumber\n",
    "import re\n",
    "\n",
    "\n",
    "# python PDFProcessing/PDFProccesing.py > outputs/refoutput.txt\n",
    "\n",
    "text_list = []\n",
    "\n",
    "with pdfplumber.open(\"PDF_docs/doc_0.pdf\") as pdf:\n",
    "    for page in pdf.pages:\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            text_list.append(text)\n",
    "            text = text.join(text_list)\n",
    "text\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = re.split(r\"\\breferences\\b\", text, flags=re.IGNORECASE, maxsplit=1)\n",
    "\n",
    "body = parts[0].strip()  # Everything before \"References\"\n",
    "reference = parts[1].strip() if len(parts) > 1 else \"\"  # Everything after \"References\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pdfplumber.open(\"PDF_docs/doc_2.pdf\")\n",
    "pdf.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pdfplumber.open(\"PDF_docs/doc_0.pdf\")\n",
    "metadata = pdf.metadata  # Extrahiere Metadaten\n",
    "if metadata and \"Title\" in metadata and metadata[\"Title\"]:\n",
    "    print( f\"Titel: {metadata['Title']}\")\n",
    "else: \n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pdfplumber.open(\"PDF_docs/doc_1.pdf\") as pdf:\n",
    "    metadata = pdf.metadata\n",
    "    print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import ChatResponse, chat\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "from langchain_chroma import Chroma\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_dir = \"PDF_docs/\"\n",
    "\n",
    "pdf_files = os.listdir(pdf_dir)\n",
    "\n",
    "# Liste zum Speichern aller geladenen Dokumente\n",
    "all_docs = []\n",
    "\n",
    "# Alle PDFs im Verzeichnis durchgehen und laden\n",
    "for pdf_file in pdf_files:\n",
    "    pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    docs = loader.load()\n",
    "    all_docs.extend(docs)  # Alle Dokumente speichern\n",
    "\n",
    "# ÃœberprÃ¼fen, ob Dokumente geladen wurden\n",
    "print(f\"{len(all_docs)} Dokumente geladen.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(all_docs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"llama3.2:latest\")  # Korrekte Embeddings-Funktion\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "persistent_client = chromadb.PersistentClient()\n",
    "collection = persistent_client.get_or_create_collection(\"collection_name\")\n",
    "\n",
    "collection.add(ids=[len(all_docs)], documents=[\"a\", \"b\", \"c\"])\n",
    "\n",
    "vector_store_from_client = Chroma(\n",
    "    client=persistent_client,\n",
    "    collection_name=\"collection_name\",\n",
    "    embedding_function=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=1,\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=2,\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=3,\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=4,\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=5,\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=6,\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=7,\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=8,\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=9,\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=10,\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import chromadb\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# # ðŸ“Œ Schritt 1: PDFs laden\n",
    "# pdf_dir = \"PDF_docs/\"\n",
    "# pdf_files = [f for f in os.listdir(pdf_dir) if f.endswith(\".pdf\")]  # Nur PDFs\n",
    "\n",
    "# all_docs = []\n",
    "# for pdf_file in pdf_files:\n",
    "#     pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "#     loader = PyPDFLoader(pdf_path)\n",
    "#     docs = loader.load()\n",
    "#     all_docs.extend(docs)  # Dokumente speichern\n",
    "\n",
    "# print(f\"âœ… {len(all_docs)} Dokumente geladen.\")\n",
    "\n",
    "# # ðŸ“Œ Schritt 2: Embeddings erstellen\n",
    "# embeddings = OllamaEmbeddings(model=\"llama3.2:latest\")  # Korrekte Embeddings\n",
    "\n",
    "# # ðŸ“Œ Schritt 3: ChromaDB persistent speichern\n",
    "# persistent_client = chromadb.PersistentClient(path=\"./chroma_langchain_db\")  # Verzeichnis fÃ¼r Speicherung\n",
    "# collection = persistent_client.get_or_create_collection(\"collection_name\")\n",
    "\n",
    "# ðŸ“Œ Schritt 4: Dokumente zu ChromaDB hinzufÃ¼gen\n",
    "doc_texts = [doc.page_content for doc in all_docs]  # Extrahiere den Text\n",
    "doc_ids = [f\"doc_{i}\" for i in range(len(doc_texts))]  # Einzigartige IDs\n",
    "\n",
    "collection.add(ids=doc_ids, documents=doc_texts)  # Speichern in ChromaDB\n",
    "\n",
    "# ðŸ“Œ Schritt 5: Chroma-VectorStore mit gespeicherten Daten initialisieren\n",
    "vector_store_from_client = Chroma(\n",
    "    persist_directory=\"./chroma_langchain_db\",\n",
    "    collection_name=\"collection_name\",\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "print(\"âœ… ChromaDB erfolgreich mit PDFs initialisiert!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"PDF_docs/\"\n",
    "\n",
    "def save_doc(file_path):\n",
    "    # Schritt 1: PDFs laden\n",
    "    file_path = \"PDF_docs/\"\n",
    "    pdf_files = [f for f in os.listdir(file_path) if f.endswith(\".pdf\")]  # Nur PDFs\n",
    "\n",
    "    all_docs = []\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(file_path, pdf_file)\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        docs = loader.load()\n",
    "        all_docs.extend(docs)  # Dokumente speichern\n",
    "    \n",
    "    return all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs = save_doc(file_path=file_path)\n",
    "len(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding():\n",
    "    embeddings = OllamaEmbeddings(model=\"llama3.2:latest\")  # Korrekte Embeddings\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OllamaEmbeddings(model='llama3.2:latest', base_url=None, client_kwargs={})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = embedding() \n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(name=collection_name)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def persistent_clientChroma():\n",
    "    persistent_client = chromadb.PersistentClient(path=\"./chroma_langchain_db\")  # Verzeichnis fÃ¼r Speicherung\n",
    "    collection = persistent_client.get_or_create_collection(\"collection_name\")\n",
    "    return collection\n",
    "\n",
    "collection = persistent_clientChroma()\n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_doc_to_Chroma():\n",
    "    doc_texts = [doc.page_content for doc in all_docs]  # Extrahiere den Text\n",
    "    doc_ids = [f\"doc_{i}\" for i in range(len(doc_texts))]  # Einzigartige IDs\n",
    "\n",
    "    collection_db = collection.add(ids=doc_ids, documents=doc_texts)  # Speichern in ChromaDB\n",
    "    return collection_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_db = add_doc_to_Chroma()\n",
    "collection_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_store_from_clientChroma():\n",
    "    # ðŸ“Œ Schritt 5: Chroma-VectorStore mit gespeicherten Daten initialisieren\n",
    "    vector_store_from_client = Chroma(\n",
    "        persist_directory=\"./chroma_langchain_db\",\n",
    "        collection_name=\"collection_name\",\n",
    "        embedding_function=embeddings,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
